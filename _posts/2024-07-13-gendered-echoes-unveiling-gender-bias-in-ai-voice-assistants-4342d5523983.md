---
title: "Gendered Echoes: Unveiling Gender Bias in AI Voice Assistants"
date: 2024-07-13
categories:
  - blog
  - research
tags:
  - gender bias
  - voice assistants
---


<p>Original Medium post: <a href="https://medium.com/@nityaakalra5/gendered-echoes-unveiling-gender-bias-in-ai-voice-assistants-4342d5523983" target="_blank" rel="noopener">Gendered Echoes: Unveiling Gender Bias in AI Voice Assistants</a>.</p>

<blockquote><a href="https://www.brookings.edu/articles/how-ai-bots-and-voice-assistants-reinforce-gender-bias/.">“ When we add a human name, face, or voice [to technology] … it reflects the biases in the viewpoints of the teams that built it.</a>”</blockquote><p>Think about the voice that guides you through your day. It reminds you of appointments, plays your favourite music, and even controls your smart lights. But have you ever stopped to consider the gender of that voice? Interestingly, most AI assistants are female. This isn’t a random choice after all and with the ever-increasing use of AI voice assistants since the COVID-19 pandemic <a href="https://voicebot.ai/2020/05/07/coronavirus-lockdown-is-upping-voice-assistant-interaction-in-the-uk-even-when-it-ends-report/.">(a jump from 41% to 63%</a>), it’s a pattern worth exploring.</p><p>This curious trend of female-voiced AI assistants raises some interesting questions. Does it simply reflect user preference? Or could there be deeper forces at play?</p><p>At times, these AI voice assistants sound suspiciously like a friendly neighbourhood customer service rep. There’s a reason for that, and it’s not just about sounding pleasant. Research suggests people might perceive female voices as more <a href="https://philarchive.org/archive/ELDSSA-2">trustworthy and helpful</a>. But is this preference for female voices entirely harmless? A study by <a href="https://unesdoc.unesco.org/ark:/48223/pf0000367416">UNESCO</a> challenges this assumption, suggesting it might reinforce traditional gender roles, implying that women are better suited to supportive, service-oriented occupations.</p><p>As a result, this issue has been extensively researched and talked about. While there have been suggestions for developing more gender-neutral voice assistants, it remains uncertain whether this alone would address the deeply ingrained societal stereotypes.</p><p>This isn’t about pointing fingers at designers, but about understanding the ‘<em>why’</em> behind these choices. Understanding AI bias alone may not dismantle it entirely, but hey, it’s a small step towards an inclusive future for technology :)</p><p>This first post dives into the historical roots of gender bias in AI voice assistants.</p><h3>From Telephone Operators to AI Assistants: A Historical Look at Female Voices in Technology</h3><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*I7yk1SMHdyoOjq7gMBBORg.jpeg" /><figcaption><a href="https://commons.wikimedia.org/wiki/File:Photograph_of_Women_Working_at_a_Bell_System_Telephone_Switchboard_(3660047829).jpg">Women Telephone Operators in the 1880s</a></figcaption></figure><p>Let’s rewind to a time before smartphones and smart speakers, when <em>‘phone’</em> was still a brand new invention and connecting with someone required the guiding hand (or rather, voice) of a human intermediary: the telephone operator.</p><p>Back in 1878, Alexander Graham Bell himself, the mind behind the telephone, championed a switch — replacing the men initially hired as operators with women. This is when <a href="https://time.com/4011936/emma-nutt/">Emma Nutt</a> became history’s first female telephone operator.</p><p>The trend persisted, and by the end of the 1880s, women’s voices were becoming the go-to choice for communication roles beyond the switchboard. They were taking centre stage in new media like radio and television as well. This shift, however, wasn’t driven by gender equality but by a perception of female voices being more <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1559-1816.1997.tb00275.x">pleasant and suitable for service roles</a>.</p><p>Fast forward to the digital age, the legacy of the<em> ‘female voice as ideal’ </em>lives on. The pool of readily available recorded voices for AI assistants was <a href="https://www.adaptworldwide.com/insights/2021/gender-bias-in-ai-why-voice-assistants-are-female">heavily skewed towards women</a>, simply because that’s what dominated communication technology for so long. This historical quirk, while unintentional, has limited the voice options for the training data available to developers of AI voice assistants today.</p><p>So, what does this mean for the future of AI assistants? Are we stuck with this stereotype, or is there room for more diversity? We’ll explore these questions and how this historical context continues to influence the design of these voice assistants in the next post.</p><h4>References</h4><ol><li>C. Chin-Rothmann and M. Robison, “How AI bots and voice assistants reinforce gender bias,” Brookings, 23-Nov-2020. [Online]. Available: <a href="https://www.brookings.edu/articles/how-ai-bots-and-voice-assistants-reinforce-gender-bias/.">https://www.brookings.edu/articles/how-ai-bots-and-voice-assistants-reinforce-gender-bias/.</a></li><li>E. H. Schwartz, “Coronavirus lockdown is upping voice assistant interaction in the UK: Report,” Voicebot.ai, 07-May-2020. [Online]. Available: <a href="https://voicebot.ai/2020/05/07/coronavirus-lockdown-is-upping-voice-assistant-interaction-in-the-uk-even-when-it-ends-report/.">https://voicebot.ai/2020/05/07/coronavirus-lockdown-is-upping-voice-assistant-interaction-in-the-uk-even-when-it-ends-report/.</a></li><li>A. Elder, “Siri, stereotypes, and the mechanics of sexism,” Fem. Philos. Q., vol. 8, no. 3/4, 2022.</li><li>“I’d Blush If I Could: Closing Gender Divides in Digital Skills Through Education,” UNESCO, 2019.</li><li>“The woman who made history by answering the phone,” Time.</li><li>E. Fisher, “Gender bias in AI: Why voice assistants are female,” Adapt. [Online]. Available: <a href="https://www.adaptworldwide.com/insights/2021/gender-bias-in-ai-why-voice-assistants-are-female.">https://www.adaptworldwide.com/insights/2021/gender-bias-in-ai-why-voice-assistants-are-female.</a></li><li>C. Nass, Y. Moon, and N. Green, “Are machines gender neutral? Gender‐stereotypic responses to computers with voices,” J. Appl. Soc. Psychol., vol. 27, no. 10, pp. 864–876, 1997.</li></ol><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=4342d5523983" width="1" height="1" alt="">
